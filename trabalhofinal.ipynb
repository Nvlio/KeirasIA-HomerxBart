{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Trabalho Final de TI\n",
        "Disciplina: TÓPICOS EM TECNOLOGIA DA INFORMAÇÃO\n",
        "\n",
        "Professor: MÁRIO AUGUSTO PAZOTI\n",
        "\n",
        "Curso:Engenhária de software\n",
        "\n",
        "\n",
        "___\n",
        "\n",
        "Aluno:\n",
        "---\n",
        "Nome: João Gabriel Caires fernandes\n",
        "\n",
        "RA:9332111030\n"
      ],
      "metadata": {
        "id": "ws8R91eE4G9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separei os exercícios para cada abordagem, seguindo da primeira abordagem para a segunda com o fim sendo o comentário sobre ambas as abordagens assim como seus prós e contras."
      ],
      "metadata": {
        "id": "xvj3SxOs5JRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 exercicio\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1.   Abordagem por Imagens\n",
        "\n",
        "     A abordagem por imagem, contem apenas as imagens dos personagens dividido em imagens para treinar e imagens para testar, com isso você deixa o trabalho de encontrar a diferença entre os personagens para a I.A. que por meio das tecnicas para lidar com imagens vai encontrar a diferença entre ambos.\n",
        "     \n",
        "\n",
        "2.   Abordagem por texto\n",
        "\n",
        "    Já a abordagem por texto você já dá o resultado de cada valor e passa a resposta, deixando para a I.A. apenas verificar os valores para cada parametro e entender o que diferencia cada personagem, pulando o trabalho que ela teria de filtrar e ir diminuindo a imagem até conseguir encontrar os dados por si mesma.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ug5tyebv4PUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I.A. para processar a primeira abordagem"
      ],
      "metadata": {
        "id": "ksL3gBs56QD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar itens necessários"
      ],
      "metadata": {
        "id": "2kJBUUCoR1fm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpzS1fBB4F1W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder as le\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar itens para a I.A."
      ],
      "metadata": {
        "id": "mzyQ3UAMRs3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "AhP9UVkUBwb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separação dos dados da tabela"
      ],
      "metadata": {
        "id": "Nx6ZVR1Q_lr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados = open('/content/drive/MyDrive/IA keras]/Abordagens/personagens_descritores.csv','r')\n",
        "caracteristicas=[]\n",
        "valor=[]\n",
        "resposta=[]\n",
        "for indice,linha in enumerate(csv.reader(dados)):\n",
        "  if indice==0:\n",
        "    caracteristicas = linha\n",
        "  else:\n",
        "    valor.append(linha[0:6])\n",
        "    resposta.append(linha[6])\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "J5zoVr4Y7Dpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparação dos conjuntos de treino\n",
        "2 exercício para abordagem 1:\n",
        "---\n",
        "---\n",
        "\n",
        "Aqui ocorrerá:\n",
        "\n",
        "\n",
        "1.   Separação das respostas e valores\n",
        "2.   Formatação das listas para um tipo fácil para a I.A.\n",
        "3.   Formatação dos valoes da lista valores para uma escala (0,1)\n",
        "4.   Separação das listas (valores e respostas) em treino e teste\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VYHd0_qXR6w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valor = np.array(valor)\n",
        "valor_escalado=[]\n",
        "\n",
        "valor,resposta = shuffle(valor,resposta)\n",
        "\n",
        "escala = MinMaxScaler(feature_range=(0,1))\n",
        "valores_escalados = escala.fit_transform(valor.reshape(-1,1))\n",
        "\n",
        "valor_escalado=[]\n",
        "itens_lista=[]\n",
        "for i in range(len(valores_escalados)):\n",
        "  itens_lista.append(valores_escalados[i][0])\n",
        "  if (i+1)%6==0 :\n",
        "    valor_escalado.append(itens_lista)\n",
        "    itens_lista=[]\n",
        "\n",
        "valor_escalado = np.array(valor_escalado).reshape((-1,6))\n",
        "\n",
        "\"\"\"resposta\"\"\"\n",
        "classes={\"Bart\":0,\"Homer\":1}\n",
        "resposta_bi = []\n",
        "for i in range(len(resposta)):\n",
        "  resposta_bi.append(classes[resposta[i]])\n",
        "\n",
        "resposta_bi = np.array(resposta_bi)\n",
        "\n",
        "\n",
        "valor_treino,valor_teste,resposta_treino,resposta_teste = train_test_split(valor_escalado,resposta_bi,test_size=0.25)\n",
        "\n",
        "print(len(valor_treino),len(valor_teste))\n",
        "print(resposta_treino,len(resposta_teste))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R5bDwy6v_FCX",
        "outputId": "f142f1f4-f445-4368-d4c9-a00ee879a992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219 74\n",
            "[0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0\n",
            " 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0\n",
            " 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
            " 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1] 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inicio da I.A. primeira abordagem\n",
        "\n",
        "3 exercício para abordagem 1\n",
        "---\n",
        "---\n",
        "\n",
        "O tipo de rede Neural escolhida para a primeira abordagem vai ser a **Multicamadas Perceptron**:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  visto que a abordagem um poderá ocorrer casos onde apenas uma camada não retornará a resposta correta, sendo ncessário mais camadas. e por não ser uma imagem não é necessário a rede convolucional por isso escolhi esse tipo de rede neural.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> A 4 resposta está nos comentários do codigo abaixo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hEj72EKuSB7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Sequential([\n",
        "    Dense(units=6,input_shape=(6,),activation=\"relu\"),\n",
        "    Dense(units=12,activation=\"relu\"),\n",
        "    Dense(units=2,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Motivos para a configuração escolhida:\n",
        "#escolhi duas camadas ocultas pois vejo ser um numero bom para que a resposta seja satisfatória sem que ocorre overfitting\n",
        "#quantidade de unidades foi feita por meio dos seguintes parametros:\n",
        "#1 dense total de quantidade da lista de entrada = 6\n",
        "#2 dense quantidade de entrada = 6 e quantidade de saida = 2 (6 * 2 = 12)\n",
        "#dense quantidade de saídas =2\n",
        "\n",
        "\n",
        "modelo.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qadcCZMORsce",
        "outputId": "95493c4a-05a2-4a0f-ad05-d5bbcb1e0c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_34 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 12)                84        \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 2)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 152 (608.00 Byte)\n",
            "Trainable params: 152 (608.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(optimizer=Adam(learning_rate=0.0001),loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "AR8cO6uRU1Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Treinamento da rede\n",
        "5 exercício\n",
        "\n",
        "___\n",
        "\n",
        "explicação da configuração:\n",
        "\n",
        "1.   x e y são a entrada e rótulos\n",
        "2.   batch = 5 acho batch um numero que acho o suficiente para pegar o melhor resultado.\n",
        "3.   epochs = 120 foi escolhido pelo fato de querer melhorar a acuracia do treinamento da I.A. além de não ser muito treinamento para ocasionar algum overffitng\n",
        "4.   Verbose = 2, escolhido e definido para poder ver com detalhes as informações de cada epoca.\n",
        "\n"
      ],
      "metadata": {
        "id": "EAD8ur-Ac2go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.fit(x=valor_treino,y=resposta_treino,batch_size=5,epochs=120,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aRJd6fogckya",
        "outputId": "7028a77c-b89e-4b73-c4c9-ff98bd20cd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "44/44 - 1s - loss: 0.6935 - accuracy: 0.6804 - 1s/epoch - 28ms/step\n",
            "Epoch 2/120\n",
            "44/44 - 0s - loss: 0.6905 - accuracy: 0.6804 - 131ms/epoch - 3ms/step\n",
            "Epoch 3/120\n",
            "44/44 - 0s - loss: 0.6881 - accuracy: 0.6667 - 138ms/epoch - 3ms/step\n",
            "Epoch 4/120\n",
            "44/44 - 0s - loss: 0.6858 - accuracy: 0.6621 - 149ms/epoch - 3ms/step\n",
            "Epoch 5/120\n",
            "44/44 - 0s - loss: 0.6837 - accuracy: 0.6575 - 198ms/epoch - 4ms/step\n",
            "Epoch 6/120\n",
            "44/44 - 0s - loss: 0.6816 - accuracy: 0.6484 - 123ms/epoch - 3ms/step\n",
            "Epoch 7/120\n",
            "44/44 - 0s - loss: 0.6796 - accuracy: 0.6484 - 164ms/epoch - 4ms/step\n",
            "Epoch 8/120\n",
            "44/44 - 0s - loss: 0.6776 - accuracy: 0.6393 - 162ms/epoch - 4ms/step\n",
            "Epoch 9/120\n",
            "44/44 - 0s - loss: 0.6756 - accuracy: 0.6393 - 151ms/epoch - 3ms/step\n",
            "Epoch 10/120\n",
            "44/44 - 0s - loss: 0.6736 - accuracy: 0.6347 - 129ms/epoch - 3ms/step\n",
            "Epoch 11/120\n",
            "44/44 - 0s - loss: 0.6715 - accuracy: 0.6301 - 136ms/epoch - 3ms/step\n",
            "Epoch 12/120\n",
            "44/44 - 0s - loss: 0.6693 - accuracy: 0.6210 - 132ms/epoch - 3ms/step\n",
            "Epoch 13/120\n",
            "44/44 - 0s - loss: 0.6672 - accuracy: 0.6210 - 139ms/epoch - 3ms/step\n",
            "Epoch 14/120\n",
            "44/44 - 0s - loss: 0.6649 - accuracy: 0.6210 - 162ms/epoch - 4ms/step\n",
            "Epoch 15/120\n",
            "44/44 - 0s - loss: 0.6627 - accuracy: 0.6210 - 152ms/epoch - 3ms/step\n",
            "Epoch 16/120\n",
            "44/44 - 0s - loss: 0.6604 - accuracy: 0.6164 - 156ms/epoch - 4ms/step\n",
            "Epoch 17/120\n",
            "44/44 - 0s - loss: 0.6581 - accuracy: 0.6164 - 161ms/epoch - 4ms/step\n",
            "Epoch 18/120\n",
            "44/44 - 0s - loss: 0.6557 - accuracy: 0.6164 - 148ms/epoch - 3ms/step\n",
            "Epoch 19/120\n",
            "44/44 - 0s - loss: 0.6532 - accuracy: 0.6164 - 129ms/epoch - 3ms/step\n",
            "Epoch 20/120\n",
            "44/44 - 0s - loss: 0.6507 - accuracy: 0.6164 - 139ms/epoch - 3ms/step\n",
            "Epoch 21/120\n",
            "44/44 - 0s - loss: 0.6481 - accuracy: 0.6164 - 138ms/epoch - 3ms/step\n",
            "Epoch 22/120\n",
            "44/44 - 0s - loss: 0.6455 - accuracy: 0.6164 - 149ms/epoch - 3ms/step\n",
            "Epoch 23/120\n",
            "44/44 - 0s - loss: 0.6428 - accuracy: 0.6164 - 160ms/epoch - 4ms/step\n",
            "Epoch 24/120\n",
            "44/44 - 0s - loss: 0.6401 - accuracy: 0.6164 - 151ms/epoch - 3ms/step\n",
            "Epoch 25/120\n",
            "44/44 - 0s - loss: 0.6372 - accuracy: 0.6164 - 143ms/epoch - 3ms/step\n",
            "Epoch 26/120\n",
            "44/44 - 0s - loss: 0.6343 - accuracy: 0.6164 - 160ms/epoch - 4ms/step\n",
            "Epoch 27/120\n",
            "44/44 - 0s - loss: 0.6313 - accuracy: 0.6164 - 143ms/epoch - 3ms/step\n",
            "Epoch 28/120\n",
            "44/44 - 0s - loss: 0.6283 - accuracy: 0.6210 - 172ms/epoch - 4ms/step\n",
            "Epoch 29/120\n",
            "44/44 - 0s - loss: 0.6252 - accuracy: 0.6164 - 171ms/epoch - 4ms/step\n",
            "Epoch 30/120\n",
            "44/44 - 0s - loss: 0.6221 - accuracy: 0.6210 - 146ms/epoch - 3ms/step\n",
            "Epoch 31/120\n",
            "44/44 - 0s - loss: 0.6190 - accuracy: 0.6210 - 81ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "44/44 - 0s - loss: 0.6157 - accuracy: 0.6210 - 85ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "44/44 - 0s - loss: 0.6125 - accuracy: 0.6210 - 92ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "44/44 - 0s - loss: 0.6093 - accuracy: 0.6210 - 79ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "44/44 - 0s - loss: 0.6061 - accuracy: 0.6256 - 79ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "44/44 - 0s - loss: 0.6028 - accuracy: 0.6210 - 82ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "44/44 - 0s - loss: 0.5995 - accuracy: 0.6347 - 88ms/epoch - 2ms/step\n",
            "Epoch 38/120\n",
            "44/44 - 0s - loss: 0.5962 - accuracy: 0.6347 - 81ms/epoch - 2ms/step\n",
            "Epoch 39/120\n",
            "44/44 - 0s - loss: 0.5929 - accuracy: 0.6393 - 85ms/epoch - 2ms/step\n",
            "Epoch 40/120\n",
            "44/44 - 0s - loss: 0.5896 - accuracy: 0.6393 - 86ms/epoch - 2ms/step\n",
            "Epoch 41/120\n",
            "44/44 - 0s - loss: 0.5863 - accuracy: 0.6393 - 76ms/epoch - 2ms/step\n",
            "Epoch 42/120\n",
            "44/44 - 0s - loss: 0.5832 - accuracy: 0.6393 - 87ms/epoch - 2ms/step\n",
            "Epoch 43/120\n",
            "44/44 - 0s - loss: 0.5796 - accuracy: 0.6393 - 76ms/epoch - 2ms/step\n",
            "Epoch 44/120\n",
            "44/44 - 0s - loss: 0.5763 - accuracy: 0.6484 - 181ms/epoch - 4ms/step\n",
            "Epoch 45/120\n",
            "44/44 - 0s - loss: 0.5729 - accuracy: 0.6530 - 175ms/epoch - 4ms/step\n",
            "Epoch 46/120\n",
            "44/44 - 0s - loss: 0.5695 - accuracy: 0.6530 - 197ms/epoch - 4ms/step\n",
            "Epoch 47/120\n",
            "44/44 - 0s - loss: 0.5662 - accuracy: 0.6530 - 175ms/epoch - 4ms/step\n",
            "Epoch 48/120\n",
            "44/44 - 0s - loss: 0.5628 - accuracy: 0.6530 - 158ms/epoch - 4ms/step\n",
            "Epoch 49/120\n",
            "44/44 - 0s - loss: 0.5596 - accuracy: 0.6530 - 163ms/epoch - 4ms/step\n",
            "Epoch 50/120\n",
            "44/44 - 0s - loss: 0.5560 - accuracy: 0.6575 - 258ms/epoch - 6ms/step\n",
            "Epoch 51/120\n",
            "44/44 - 0s - loss: 0.5526 - accuracy: 0.6621 - 213ms/epoch - 5ms/step\n",
            "Epoch 52/120\n",
            "44/44 - 0s - loss: 0.5493 - accuracy: 0.6667 - 184ms/epoch - 4ms/step\n",
            "Epoch 53/120\n",
            "44/44 - 0s - loss: 0.5459 - accuracy: 0.6667 - 140ms/epoch - 3ms/step\n",
            "Epoch 54/120\n",
            "44/44 - 0s - loss: 0.5426 - accuracy: 0.6667 - 212ms/epoch - 5ms/step\n",
            "Epoch 55/120\n",
            "44/44 - 0s - loss: 0.5391 - accuracy: 0.6895 - 258ms/epoch - 6ms/step\n",
            "Epoch 56/120\n",
            "44/44 - 0s - loss: 0.5360 - accuracy: 0.6986 - 166ms/epoch - 4ms/step\n",
            "Epoch 57/120\n",
            "44/44 - 0s - loss: 0.5324 - accuracy: 0.7032 - 137ms/epoch - 3ms/step\n",
            "Epoch 58/120\n",
            "44/44 - 0s - loss: 0.5290 - accuracy: 0.7078 - 141ms/epoch - 3ms/step\n",
            "Epoch 59/120\n",
            "44/44 - 0s - loss: 0.5257 - accuracy: 0.7078 - 185ms/epoch - 4ms/step\n",
            "Epoch 60/120\n",
            "44/44 - 0s - loss: 0.5222 - accuracy: 0.7123 - 177ms/epoch - 4ms/step\n",
            "Epoch 61/120\n",
            "44/44 - 0s - loss: 0.5190 - accuracy: 0.7260 - 158ms/epoch - 4ms/step\n",
            "Epoch 62/120\n",
            "44/44 - 0s - loss: 0.5156 - accuracy: 0.7352 - 143ms/epoch - 3ms/step\n",
            "Epoch 63/120\n",
            "44/44 - 0s - loss: 0.5122 - accuracy: 0.7534 - 152ms/epoch - 3ms/step\n",
            "Epoch 64/120\n",
            "44/44 - 0s - loss: 0.5092 - accuracy: 0.7580 - 143ms/epoch - 3ms/step\n",
            "Epoch 65/120\n",
            "44/44 - 0s - loss: 0.5056 - accuracy: 0.7717 - 173ms/epoch - 4ms/step\n",
            "Epoch 66/120\n",
            "44/44 - 0s - loss: 0.5024 - accuracy: 0.7717 - 175ms/epoch - 4ms/step\n",
            "Epoch 67/120\n",
            "44/44 - 0s - loss: 0.4991 - accuracy: 0.7763 - 194ms/epoch - 4ms/step\n",
            "Epoch 68/120\n",
            "44/44 - 0s - loss: 0.4959 - accuracy: 0.7854 - 195ms/epoch - 4ms/step\n",
            "Epoch 69/120\n",
            "44/44 - 0s - loss: 0.4926 - accuracy: 0.7991 - 193ms/epoch - 4ms/step\n",
            "Epoch 70/120\n",
            "44/44 - 0s - loss: 0.4893 - accuracy: 0.8037 - 149ms/epoch - 3ms/step\n",
            "Epoch 71/120\n",
            "44/44 - 0s - loss: 0.4863 - accuracy: 0.8037 - 256ms/epoch - 6ms/step\n",
            "Epoch 72/120\n",
            "44/44 - 0s - loss: 0.4831 - accuracy: 0.8082 - 314ms/epoch - 7ms/step\n",
            "Epoch 73/120\n",
            "44/44 - 0s - loss: 0.4798 - accuracy: 0.8128 - 180ms/epoch - 4ms/step\n",
            "Epoch 74/120\n",
            "44/44 - 0s - loss: 0.4768 - accuracy: 0.8311 - 171ms/epoch - 4ms/step\n",
            "Epoch 75/120\n",
            "44/44 - 0s - loss: 0.4737 - accuracy: 0.8356 - 124ms/epoch - 3ms/step\n",
            "Epoch 76/120\n",
            "44/44 - 0s - loss: 0.4706 - accuracy: 0.8402 - 84ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "44/44 - 0s - loss: 0.4677 - accuracy: 0.8402 - 71ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "44/44 - 0s - loss: 0.4647 - accuracy: 0.8447 - 76ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "44/44 - 0s - loss: 0.4618 - accuracy: 0.8493 - 88ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "44/44 - 0s - loss: 0.4588 - accuracy: 0.8539 - 85ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "44/44 - 0s - loss: 0.4558 - accuracy: 0.8539 - 84ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "44/44 - 0s - loss: 0.4530 - accuracy: 0.8539 - 83ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "44/44 - 0s - loss: 0.4501 - accuracy: 0.8584 - 79ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "44/44 - 0s - loss: 0.4471 - accuracy: 0.8630 - 85ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "44/44 - 0s - loss: 0.4443 - accuracy: 0.8630 - 72ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "44/44 - 0s - loss: 0.4414 - accuracy: 0.8630 - 72ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "44/44 - 0s - loss: 0.4387 - accuracy: 0.8630 - 75ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "44/44 - 0s - loss: 0.4358 - accuracy: 0.8630 - 84ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "44/44 - 0s - loss: 0.4332 - accuracy: 0.8630 - 72ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "44/44 - 0s - loss: 0.4305 - accuracy: 0.8630 - 76ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "44/44 - 0s - loss: 0.4279 - accuracy: 0.8676 - 100ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "44/44 - 0s - loss: 0.4253 - accuracy: 0.8676 - 74ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "44/44 - 0s - loss: 0.4226 - accuracy: 0.8676 - 75ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "44/44 - 0s - loss: 0.4201 - accuracy: 0.8676 - 78ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "44/44 - 0s - loss: 0.4176 - accuracy: 0.8676 - 74ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "44/44 - 0s - loss: 0.4153 - accuracy: 0.8676 - 74ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "44/44 - 0s - loss: 0.4126 - accuracy: 0.8676 - 74ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "44/44 - 0s - loss: 0.4105 - accuracy: 0.8676 - 73ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "44/44 - 0s - loss: 0.4077 - accuracy: 0.8676 - 79ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "44/44 - 0s - loss: 0.4054 - accuracy: 0.8676 - 76ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "44/44 - 0s - loss: 0.4032 - accuracy: 0.8676 - 71ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "44/44 - 0s - loss: 0.4008 - accuracy: 0.8721 - 85ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "44/44 - 0s - loss: 0.3985 - accuracy: 0.8721 - 70ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "44/44 - 0s - loss: 0.3963 - accuracy: 0.8721 - 102ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "44/44 - 0s - loss: 0.3939 - accuracy: 0.8721 - 81ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "44/44 - 0s - loss: 0.3918 - accuracy: 0.8721 - 76ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "44/44 - 0s - loss: 0.3893 - accuracy: 0.8721 - 109ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "44/44 - 0s - loss: 0.3871 - accuracy: 0.8721 - 133ms/epoch - 3ms/step\n",
            "Epoch 109/120\n",
            "44/44 - 0s - loss: 0.3849 - accuracy: 0.8721 - 128ms/epoch - 3ms/step\n",
            "Epoch 110/120\n",
            "44/44 - 0s - loss: 0.3828 - accuracy: 0.8721 - 140ms/epoch - 3ms/step\n",
            "Epoch 111/120\n",
            "44/44 - 0s - loss: 0.3807 - accuracy: 0.8721 - 124ms/epoch - 3ms/step\n",
            "Epoch 112/120\n",
            "44/44 - 0s - loss: 0.3785 - accuracy: 0.8813 - 127ms/epoch - 3ms/step\n",
            "Epoch 113/120\n",
            "44/44 - 0s - loss: 0.3765 - accuracy: 0.8767 - 151ms/epoch - 3ms/step\n",
            "Epoch 114/120\n",
            "44/44 - 0s - loss: 0.3744 - accuracy: 0.8813 - 123ms/epoch - 3ms/step\n",
            "Epoch 115/120\n",
            "44/44 - 0s - loss: 0.3723 - accuracy: 0.8813 - 127ms/epoch - 3ms/step\n",
            "Epoch 116/120\n",
            "44/44 - 0s - loss: 0.3701 - accuracy: 0.8813 - 133ms/epoch - 3ms/step\n",
            "Epoch 117/120\n",
            "44/44 - 0s - loss: 0.3682 - accuracy: 0.8813 - 147ms/epoch - 3ms/step\n",
            "Epoch 118/120\n",
            "44/44 - 0s - loss: 0.3664 - accuracy: 0.8813 - 137ms/epoch - 3ms/step\n",
            "Epoch 119/120\n",
            "44/44 - 0s - loss: 0.3641 - accuracy: 0.8858 - 144ms/epoch - 3ms/step\n",
            "Epoch 120/120\n",
            "44/44 - 0s - loss: 0.3622 - accuracy: 0.8858 - 177ms/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7876efaa9f60>"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Teste da I.A. da abordagem 1\n",
        "\n",
        "6 exercício\n",
        "---\n",
        "___\n",
        "\n",
        "a acuracia da I.A. foi de 85%\n",
        "\n",
        "e sua matriz de confusão foi:\n",
        "\n",
        "[[40  0]\n",
        "\n",
        "[11 23]]"
      ],
      "metadata": {
        "id": "nLjqE7RnrOYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = modelo.predict(x=valor_teste,batch_size=10,verbose=0)\n",
        "resultado = np.argmax(resultado,axis=1)\n",
        "cm = confusion_matrix(y_true=resposta_teste,y_pred=resultado)\n",
        "print(f\"Acurácia: {(cm[0][0]+cm[1][1])/len(resposta_teste)}\")\n",
        "print(cm)\n",
        "sns.heatmap(cm,cmap=\"coolwarm\",annot=True,linewidth=1,fmt=\"d\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "_BuZON9erRRF",
        "outputId": "bc20ce5a-7854-45e9-ba65-8b05ce743e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.8513513513513513\n",
            "[[40  0]\n",
            " [11 23]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 abordagem"
      ],
      "metadata": {
        "id": "ZngCsSuQyPJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image as IMG\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "_IcvDAA46fgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 exercício\n",
        "_____\n",
        "Nessa parte fiz a preparação dos dados fiz 2 listas uma contendo todas as imagens do homer e bart, para treino e teste e fiz 2 listas contendo as respostas para cada dado. As respostas sendo passadas para binario."
      ],
      "metadata": {
        "id": "sWNjqG-D5NZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diretorioTest = \"/content/drive/MyDrive/IA keras]/Abordagens/dataset_personagens_imagens/dataset_personagens/test_set\"\n",
        "diretorioTrain = \"/content/drive/MyDrive/IA keras]/Abordagens/dataset_personagens_imagens/dataset_personagens/training_set\"\n",
        "\n",
        "\n",
        "categoria=[\"bart\",\"homer\"]\n",
        "\n",
        "arquivosTest =[]\n",
        "respostaTest=[]\n",
        "arquivosTrain=[]\n",
        "respostaTrain=[]\n",
        "\n",
        "arquivosTest += (os.listdir(diretorioTest+\"/bart\"))[:]\n",
        "respostaTest += ([0] * len(os.listdir(diretorioTest+\"/bart\")))\n",
        "arquivosTest += (os.listdir(diretorioTest+\"/homer\"))[:]\n",
        "respostaTest += ([1] * len(os.listdir(diretorioTest+\"/homer\")))\n",
        "\n",
        "arquivosTrain += (os.listdir(diretorioTrain+\"/bart\"))[:]\n",
        "respostaTrain += ([0] * len(os.listdir(diretorioTrain+\"/bart\")))\n",
        "arquivosTrain += (os.listdir(diretorioTrain+\"/homer\"))[:]\n",
        "respostaTrain += ([1] * len(os.listdir(diretorioTrain+\"/homer\")))\n"
      ],
      "metadata": {
        "id": "fLkOSHub7Br8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 exercício\n",
        "____\n",
        "fiz a formatação das imagens para um dado que a I.A. consiga entender"
      ],
      "metadata": {
        "id": "gwIA0_ia5m9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Treino=[]\n",
        "Teste=[]\n",
        "entrada=\"/bart/\"\n",
        "for i in range(len(arquivosTest)):\n",
        "  if (arquivosTest[i][0:4]!=\"bart\"):\n",
        "    entrada=\"/homer/\"\n",
        "  Imagem = IMG.open(diretorioTest+entrada+arquivosTest[i]).convert(\"L\")\n",
        "  Imagem = Imagem.resize((64,64))\n",
        "  Imagem = np.array(Imagem)/255.0\n",
        "  Teste.append(Imagem)\n",
        "\n",
        "entrada =\"/bart/\"\n",
        "for i in range(len(arquivosTrain)):\n",
        "  if (arquivosTrain[i][0:4]!=\"bart\"):\n",
        "    entrada = \"/homer/\"\n",
        "  Imagem = IMG.open(diretorioTrain+entrada+arquivosTrain[i]).convert(\"L\")\n",
        "  Imagem = Imagem.resize((64,64))\n",
        "  Imagem = np.array(Imagem)/255.0\n",
        "  Treino.append(Imagem)\n",
        "\n",
        "Treino,respostaTrain = shuffle(Treino,respostaTrain)\n",
        "\n",
        "Treino = np.array(Treino)\n",
        "Teste = np.array(Teste)\n",
        "respostaTrain = np.array(respostaTrain)\n",
        "respostaTest = np.array(respostaTest)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rnyr8wFqF04b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparando a I.A.\n",
        "___\n",
        "3 exercício\n",
        "---\n",
        "O tipo de rede Neural escolhida para a segunda abordagem vai ser a convolucional:\n",
        "\n",
        "Como a I.A. vai trabalhar com imagens, então é necessário que ocorra uma preparação da imagem para que a I.A. possa dar respostas satisfatórias\n",
        "\n",
        "____\n",
        "4 exercício\n",
        "---\n",
        "Motivos para a configuração escolhida:\n",
        "\n",
        "Na parte convolucional fiz 2 etapas de tratamento das imagens escolhi 64,64,1 por causa do tamanho que foi decidido para todas as imagens.\n",
        "Após a vetorização dos dados, escolhi duas camadas ocultas pois após testes verifiqueei que era a que resultava em melhores resultados da I.A.\n",
        "\n",
        "O compiler escolhi a metrica para binário visto que as respostas só podem ser 2 \"bart\" ou \"homer\"\n",
        "___\n",
        "5 exercício\n",
        "---\n",
        "explicação da configuração:\n",
        "\n",
        "x e y são a entrada e rótulos\n",
        "batch = 15 acho batch um numero que acho o suficiente para pegar o melhor resultado.\n",
        "\n",
        "epochs = 70 foi escolhido após diversos testes para encontrar o melhor numero que evitasse overfitting, chegando no 70 como sendo a epoca que ocasionava menos desse problema\n",
        "\n",
        "Verbose = 2, escolhido e definido para poder ver com detalhes as informações de cada epoca."
      ],
      "metadata": {
        "id": "ahg3SAKtCnHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modeloCnn = Sequential([\n",
        "    Conv2D(32,(3,3),input_shape=(64,64,1),activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Conv2D(32,(3,3),activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(64,activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64,activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(2,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "modeloCnn.compile(optimizer = \"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "modeloCnn.fit(x=Treino,y=respostaTrain,batch_size=15,epochs=70,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-hPaJ49CrC8",
        "outputId": "2a49fb93-2007-4014-e992-b7922e4bd946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "14/14 - 2s - loss: 1.3583 - accuracy: 0.5102 - 2s/epoch - 177ms/step\n",
            "Epoch 2/70\n",
            "14/14 - 1s - loss: 0.8608 - accuracy: 0.6633 - 1s/epoch - 103ms/step\n",
            "Epoch 3/70\n",
            "14/14 - 1s - loss: 0.5065 - accuracy: 0.7500 - 1s/epoch - 101ms/step\n",
            "Epoch 4/70\n",
            "14/14 - 1s - loss: 0.4293 - accuracy: 0.8214 - 1s/epoch - 106ms/step\n",
            "Epoch 5/70\n",
            "14/14 - 1s - loss: 0.2763 - accuracy: 0.8520 - 1s/epoch - 79ms/step\n",
            "Epoch 6/70\n",
            "14/14 - 1s - loss: 0.2582 - accuracy: 0.8469 - 852ms/epoch - 61ms/step\n",
            "Epoch 7/70\n",
            "14/14 - 1s - loss: 0.2299 - accuracy: 0.9235 - 862ms/epoch - 62ms/step\n",
            "Epoch 8/70\n",
            "14/14 - 1s - loss: 0.1532 - accuracy: 0.9439 - 834ms/epoch - 60ms/step\n",
            "Epoch 9/70\n",
            "14/14 - 1s - loss: 0.1433 - accuracy: 0.9592 - 853ms/epoch - 61ms/step\n",
            "Epoch 10/70\n",
            "14/14 - 1s - loss: 0.0969 - accuracy: 0.9643 - 838ms/epoch - 60ms/step\n",
            "Epoch 11/70\n",
            "14/14 - 1s - loss: 0.0714 - accuracy: 0.9694 - 840ms/epoch - 60ms/step\n",
            "Epoch 12/70\n",
            "14/14 - 1s - loss: 0.0690 - accuracy: 0.9643 - 1s/epoch - 77ms/step\n",
            "Epoch 13/70\n",
            "14/14 - 1s - loss: 0.0372 - accuracy: 0.9898 - 880ms/epoch - 63ms/step\n",
            "Epoch 14/70\n",
            "14/14 - 1s - loss: 0.0738 - accuracy: 0.9643 - 849ms/epoch - 61ms/step\n",
            "Epoch 15/70\n",
            "14/14 - 1s - loss: 0.1008 - accuracy: 0.9643 - 858ms/epoch - 61ms/step\n",
            "Epoch 16/70\n",
            "14/14 - 1s - loss: 0.0512 - accuracy: 0.9898 - 942ms/epoch - 67ms/step\n",
            "Epoch 17/70\n",
            "14/14 - 1s - loss: 0.0670 - accuracy: 0.9796 - 1s/epoch - 102ms/step\n",
            "Epoch 18/70\n",
            "14/14 - 1s - loss: 0.0242 - accuracy: 0.9949 - 1s/epoch - 104ms/step\n",
            "Epoch 19/70\n",
            "14/14 - 1s - loss: 0.0397 - accuracy: 0.9847 - 1s/epoch - 102ms/step\n",
            "Epoch 20/70\n",
            "14/14 - 1s - loss: 0.0173 - accuracy: 1.0000 - 1s/epoch - 87ms/step\n",
            "Epoch 21/70\n",
            "14/14 - 1s - loss: 0.0069 - accuracy: 1.0000 - 850ms/epoch - 61ms/step\n",
            "Epoch 22/70\n",
            "14/14 - 1s - loss: 0.0375 - accuracy: 0.9847 - 855ms/epoch - 61ms/step\n",
            "Epoch 23/70\n",
            "14/14 - 1s - loss: 0.0206 - accuracy: 0.9898 - 849ms/epoch - 61ms/step\n",
            "Epoch 24/70\n",
            "14/14 - 1s - loss: 0.0147 - accuracy: 0.9949 - 856ms/epoch - 61ms/step\n",
            "Epoch 25/70\n",
            "14/14 - 1s - loss: 0.0128 - accuracy: 0.9949 - 869ms/epoch - 62ms/step\n",
            "Epoch 26/70\n",
            "14/14 - 1s - loss: 0.0050 - accuracy: 1.0000 - 865ms/epoch - 62ms/step\n",
            "Epoch 27/70\n",
            "14/14 - 1s - loss: 0.0154 - accuracy: 0.9898 - 861ms/epoch - 62ms/step\n",
            "Epoch 28/70\n",
            "14/14 - 1s - loss: 0.0215 - accuracy: 0.9949 - 856ms/epoch - 61ms/step\n",
            "Epoch 29/70\n",
            "14/14 - 1s - loss: 0.0662 - accuracy: 0.9796 - 852ms/epoch - 61ms/step\n",
            "Epoch 30/70\n",
            "14/14 - 1s - loss: 0.0977 - accuracy: 0.9592 - 854ms/epoch - 61ms/step\n",
            "Epoch 31/70\n",
            "14/14 - 1s - loss: 0.1879 - accuracy: 0.9490 - 856ms/epoch - 61ms/step\n",
            "Epoch 32/70\n",
            "14/14 - 1s - loss: 0.1003 - accuracy: 0.9439 - 1s/epoch - 91ms/step\n",
            "Epoch 33/70\n",
            "14/14 - 1s - loss: 0.0843 - accuracy: 0.9592 - 1s/epoch - 100ms/step\n",
            "Epoch 34/70\n",
            "14/14 - 1s - loss: 0.0544 - accuracy: 0.9847 - 1s/epoch - 103ms/step\n",
            "Epoch 35/70\n",
            "14/14 - 1s - loss: 0.2360 - accuracy: 0.9541 - 1s/epoch - 107ms/step\n",
            "Epoch 36/70\n",
            "14/14 - 1s - loss: 0.1494 - accuracy: 0.9490 - 853ms/epoch - 61ms/step\n",
            "Epoch 37/70\n",
            "14/14 - 1s - loss: 0.0822 - accuracy: 0.9643 - 850ms/epoch - 61ms/step\n",
            "Epoch 38/70\n",
            "14/14 - 1s - loss: 0.0773 - accuracy: 0.9745 - 864ms/epoch - 62ms/step\n",
            "Epoch 39/70\n",
            "14/14 - 1s - loss: 0.0963 - accuracy: 0.9694 - 859ms/epoch - 61ms/step\n",
            "Epoch 40/70\n",
            "14/14 - 1s - loss: 0.0413 - accuracy: 0.9949 - 863ms/epoch - 62ms/step\n",
            "Epoch 41/70\n",
            "14/14 - 1s - loss: 0.0304 - accuracy: 0.9949 - 840ms/epoch - 60ms/step\n",
            "Epoch 42/70\n",
            "14/14 - 1s - loss: 0.0103 - accuracy: 0.9949 - 881ms/epoch - 63ms/step\n",
            "Epoch 43/70\n",
            "14/14 - 1s - loss: 0.0155 - accuracy: 0.9898 - 835ms/epoch - 60ms/step\n",
            "Epoch 44/70\n",
            "14/14 - 1s - loss: 0.0236 - accuracy: 0.9949 - 848ms/epoch - 61ms/step\n",
            "Epoch 45/70\n",
            "14/14 - 1s - loss: 0.0140 - accuracy: 0.9949 - 858ms/epoch - 61ms/step\n",
            "Epoch 46/70\n",
            "14/14 - 1s - loss: 0.0130 - accuracy: 0.9949 - 865ms/epoch - 62ms/step\n",
            "Epoch 47/70\n",
            "14/14 - 1s - loss: 0.0311 - accuracy: 0.9949 - 1s/epoch - 75ms/step\n",
            "Epoch 48/70\n",
            "14/14 - 1s - loss: 0.0022 - accuracy: 1.0000 - 1s/epoch - 102ms/step\n",
            "Epoch 49/70\n",
            "14/14 - 1s - loss: 0.0249 - accuracy: 0.9898 - 1s/epoch - 107ms/step\n",
            "Epoch 50/70\n",
            "14/14 - 2s - loss: 0.0016 - accuracy: 1.0000 - 2s/epoch - 119ms/step\n",
            "Epoch 51/70\n",
            "14/14 - 2s - loss: 0.0241 - accuracy: 0.9898 - 2s/epoch - 120ms/step\n",
            "Epoch 52/70\n",
            "14/14 - 2s - loss: 0.0151 - accuracy: 0.9898 - 2s/epoch - 110ms/step\n",
            "Epoch 53/70\n",
            "14/14 - 2s - loss: 0.0129 - accuracy: 0.9949 - 2s/epoch - 110ms/step\n",
            "Epoch 54/70\n",
            "14/14 - 1s - loss: 0.0035 - accuracy: 1.0000 - 903ms/epoch - 64ms/step\n",
            "Epoch 55/70\n",
            "14/14 - 1s - loss: 0.0207 - accuracy: 0.9949 - 867ms/epoch - 62ms/step\n",
            "Epoch 56/70\n",
            "14/14 - 1s - loss: 0.0242 - accuracy: 0.9949 - 846ms/epoch - 60ms/step\n",
            "Epoch 57/70\n",
            "14/14 - 1s - loss: 0.0351 - accuracy: 0.9949 - 867ms/epoch - 62ms/step\n",
            "Epoch 58/70\n",
            "14/14 - 1s - loss: 0.0121 - accuracy: 0.9949 - 845ms/epoch - 60ms/step\n",
            "Epoch 59/70\n",
            "14/14 - 1s - loss: 0.0058 - accuracy: 0.9949 - 848ms/epoch - 61ms/step\n",
            "Epoch 60/70\n",
            "14/14 - 1s - loss: 0.0095 - accuracy: 0.9949 - 854ms/epoch - 61ms/step\n",
            "Epoch 61/70\n",
            "14/14 - 1s - loss: 0.0054 - accuracy: 1.0000 - 1s/epoch - 71ms/step\n",
            "Epoch 62/70\n",
            "14/14 - 1s - loss: 0.0101 - accuracy: 0.9949 - 1s/epoch - 106ms/step\n",
            "Epoch 63/70\n",
            "14/14 - 1s - loss: 0.0078 - accuracy: 0.9949 - 1s/epoch - 102ms/step\n",
            "Epoch 64/70\n",
            "14/14 - 1s - loss: 0.0054 - accuracy: 1.0000 - 1s/epoch - 100ms/step\n",
            "Epoch 65/70\n",
            "14/14 - 1s - loss: 0.0021 - accuracy: 1.0000 - 1s/epoch - 86ms/step\n",
            "Epoch 66/70\n",
            "14/14 - 1s - loss: 0.0023 - accuracy: 1.0000 - 870ms/epoch - 62ms/step\n",
            "Epoch 67/70\n",
            "14/14 - 1s - loss: 0.0202 - accuracy: 0.9898 - 828ms/epoch - 59ms/step\n",
            "Epoch 68/70\n",
            "14/14 - 1s - loss: 0.0024 - accuracy: 1.0000 - 842ms/epoch - 60ms/step\n",
            "Epoch 69/70\n",
            "14/14 - 1s - loss: 0.0115 - accuracy: 0.9898 - 857ms/epoch - 61ms/step\n",
            "Epoch 70/70\n",
            "14/14 - 1s - loss: 0.0110 - accuracy: 0.9898 - 847ms/epoch - 61ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7feb43125660>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 exercício\n",
        "---\n",
        "a acuracia da I.A. foi de 46%\n",
        "\n",
        "> porém consegui chegar no maximo de 52%\n",
        "\n",
        "\n",
        "\n",
        "e sua matriz de confusão foi:\n",
        "\n",
        "[[22 20]\n",
        "\n",
        "[19 12]]"
      ],
      "metadata": {
        "id": "-6bxaYWC7zy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicao = modeloCnn.predict(x=Teste,batch_size=10,verbose=0)\n",
        "predicao = np.argmax(predicao,axis=1)\n",
        "cm = confusion_matrix(y_true=respostaTest,y_pred=predicao)\n",
        "print(f\"Acurácia: {(cm[0][0]+cm[1][1])/len(respostaTest)}\")\n",
        "print(cm)\n",
        "sns.heatmap(cm,cmap=\"coolwarm\",annot=True,linewidth=1,fmt=\"d\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "uuMKYRjfaX_U",
        "outputId": "df2d0cdb-eec7-49bc-cffd-52f02b70c3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.4657534246575342\n",
            "[[22 20]\n",
            " [19 12]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6 EXERCÍCIO\n",
        "\n",
        "comentando resultados\n",
        "---\n",
        "\n",
        "Percebi que a I.A. da primeira abordagem resultou em uma acurácia melhor que a obtida pela 2 abordagem, com a primeira tendo 85% e  a segunda com o seu maximo sendo 52%(nesse exemplo eu acabei conseguindo menos 46% do que eu tinha conseguido anteriormente). Acredito que provavelmente possa ser devido a alguma necessidade maior de mais fotos para poder assim dar bons resultados da segunda abordagem.\n",
        "\n",
        "Pros:\n",
        "\n",
        "\n",
        "*   1 abordagem:\n",
        "    \n",
        "    A primeira abordagem demonstrou resultados melhores do que a segunda, acredito porque vc já entrega os valores prontos para a I.A. e só a deixa trabalhar.\n",
        "\n",
        "    .\n",
        "\n",
        "*   2 abordagem:\n",
        "    \n",
        "    A segunda abordagem é mais dinamica e independente, pois você não precisa passar o numero de cada caracteristica para a I.A. pois a mesma por meio de sua propria estrutura já encontra as caracteristicas de cada foto.\n",
        "\n",
        "\n",
        "Contras:\n",
        "\n",
        "\n",
        "*   1 abordagem:\n",
        "   \n",
        "    A primeira abordagem você precisaria ter dados que já deixassem explicito o valor de cada caracteristica limitando bastante a variedade de dados que poderiam ser usados para a I.A.\n",
        "\n",
        "    .\n",
        "\n",
        "*   2 abordagem:\n",
        "\n",
        "    A segunda abordagem por conta de vc deixar a cargo da I.A. encontrar as diferenças e caracteristicas unicas de cada individuo, acaba se criando uma necessidade de mais dados de entrada, se comparado com a primeira.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y2eXLZDn8Gcu"
      }
    }
  ]
}